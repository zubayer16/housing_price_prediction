# -*- coding: utf-8 -*-
"""422_Project_Housing_Price_Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aHyv-rSzVbclZgZcy3cKySyWn7X00mhq

#**Housing Price Predictor Using Linear Regression**

---

**Brief description of all columns in dataset**

* id : A notation for a house

* date: Date house was sold

* price: Price is prediction target

* bedrooms: Number of bedrooms

* bathrooms: Number of bathrooms

* sqft_living: Square footage of the home

* sqft_lot: Square footage of the lot

* floors :Total floors (levels) in house

* waterfront :House which has a view to a waterfront

* view: Has been viewed

* condition :How good the condition is overall

* grade: overall grade given to the housing unit, based on King County grading system

* sqft_above : Square footage of house apart from basement

* sqft_basement: Square footage of the basement

* yr_built : Built Year

* yr_renovated : Year when house was renovated

* zipcode: Zip code

* lat: Latitude coordinate

* long: Longitude coordinate

* sqft_living15 : Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area

* sqft_lot15 : LotSize area in 2015(implies-- some renovations)
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Importing all the libraries needed for this project**"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler,PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.impute import SimpleImputer
# %matplotlib inline

"""#Data Visualization
Reading the CSV file using Pandas
"""

houses = pd.read_csv('/content/kc_house_data_NaN (1).csv')
houses.head()

print("Keys of my dataset",houses.keys())

print('Rows : ',houses.shape[0],'Columns : ',houses.shape[1])

houses.dtypes

houses.describe()

sns.boxplot(x=houses["waterfront"],y=houses["price"])

sns.regplot('sqft_above','price',data=houses)

houses["floors"].value_counts().to_frame()

"""#Data Pre-Processing

Replacing missing values (NaN) using mean of particular columns
"""

houses.isnull().sum()

impute = SimpleImputer(missing_values=np.nan, strategy='mean')
impute.fit(houses[['bedrooms']])
houses['bedrooms'] = impute.transform(houses[['bedrooms']])

houses.isnull().sum()

impute = SimpleImputer(missing_values=np.nan, strategy='mean')
impute.fit(houses[['bathrooms']])
houses['bathrooms'] = impute.transform(houses[['bathrooms']])

houses.isnull().sum()

houses['bedrooms']

houses.drop(["Unnamed: 0","id"],axis=1,inplace=True) #Dropping the unnamed column

houses.head()

"""**All columns Correlation with Price (Prediction Target)**"""

houses.corr()['price'].sort_values()

"""**All columns Correlation with each other**"""

houses_corr = houses.corr() 
houses_corr

"""**Heatmap**"""

sns.heatmap(houses_corr, cmap = 'inferno')

houses.drop(["long","yr_built"],axis=1,inplace=True)  #Very low corelation

houses

print("Keys of my dataset",houses.keys())

"""#Model Evaluation & Refinement

**Training and Testing split**

"""

features =["floors", "waterfront","lat" ,"bedrooms" ,"sqft_basement" ,"view" ,"bathrooms","sqft_living15","sqft_above","grade","sqft_living"]    
X = houses[features]
Y = houses['price']

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1)


print("number of test samples:", x_test.shape[0])
print("number of training samples:",x_train.shape[0])

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler() #For lowering the variance by bringing them in between 0 and 1

scaler.fit(x_train)

x_train = scaler.transform(x_train)

print(x_train.min(axis=0))

print(x_train.max(axis=0))

x_test = scaler.transform(x_test)

"""**Linear Regression**"""

lm = LinearRegression()
lm.fit(x_train,y_train)
lm.score(x_train,y_train)

Input=[('scale',StandardScaler()),('polynomial', PolynomialFeatures(include_bias=False)),('model',LinearRegression())]

"""**Pipeline**"""

pipe=Pipeline(Input)
pipe.fit(x_train,y_train)
pipe.score(x_train,y_train)

"""**Prediction using Linear Regression**"""

y_pred = lm.predict(x_test)
y_pred

"""**Prediction using Pipeline**"""

y_pred_pipe=pipe.predict(x_test)
y_pred_pipe

"""**Actual & Predicted test data using Linear Regression**"""

acc = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
acc

"""**Actual & Predicted test data using Pipeline**"""

acc2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_pipe})
acc2

"""#Graph of Actual value Vs Prediction"""

df1 = acc.head(25)
df1.plot(kind='bar',figsize=(16,10))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.title("Actual value VS Prediction using linear regression")
plt.xlabel("Index of x_test")
plt.ylabel("Price")
plt.show()

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

df1 = acc2.head(25)
df1.plot(kind='bar',figsize=(16,10))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.title("Accuracy VS Prediction using pipeline")
plt.xlabel("Index of x_test")
plt.ylabel("Price")
plt.show()

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_pipe))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_pipe))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_pipe)))

